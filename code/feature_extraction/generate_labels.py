"""
This script generates the labels for the training data. The labels are generated from a csv file that contains the
annotations for the training data. The annotations are in the form of a csv file with the following columns:
    - filename: the name of (.wav) audio file
    - event_label: the label of the event (speech error)
    - start_time: the start time of the event
    - end_time: the end time of the event
Each array represents a phrase in the audio file (padded to 10 seconds). The features are saved in a .npy file. The phrases are extracted from the audio file using
the timestamps provided in the transcript file generated by WhisperX. Each line in the transcript file contains the following information:
    - start: the start time of the audio segment
    - end: the end time of the audio segment
    - text: the text of the audio segment
The .csv file names must match the audio file names.
    
The labels are generated by checking if the audio file contains the event. If the audio file contains the event, the
label is set to 1, otherwise the label is set to 0.

The labels are saved in a .npy file.

Usage:
    python generate_labels.py --annotations_path <path_to_annotations> --audio_path <path_to_audio_files> --transcript_dir <path_to_transcript_directory> --output_dir <path_to_output_directory> --sr <sample_rate>
    
    - wav_list (str): List of audio files to extract features from.
    - annotation_path (str): Path to the csv file containing the annotations.
    - transcript_dir (str): Directory containing the transcript files generated by WhisperX.
    - feature_dir (str): Directory containing the audio features (.npy files) generated by the feature extraction script.
    - label_dir (str): Directory where the labels will be saved.
    - label_info_dir (str): Directory where the labels information will be saved.
    - feature_config (str): Path to the feature configuration file.
    - n_process (int): Number of processes to use for feature extraction.
    
Example:
    python generate_labels.py --wav_list data/metadata/wav_list.lst --annotation_path data/metadata/dataset.csv --transcript_dir data/whisperX --feature_dir data/features --label_dir data/labels --feature_config config/feature_config.cfg --n_process 4
"""

import os
import argparse
import numpy as np
import pandas as pd
import configparser
import multiprocessing
import csv
from typing import List


class LabelEncoder:
    def __init__(self, config_path: str) -> None:
        self.config_path = config_path
        self.sr = None
        self.unique_labels = []
        self.labels_info_df = None

        self._init_config()

    def _init_config(self) -> None:
        """
        Initialize the configuration file. To extract the same sampling rate used
        in the feature extraction process.

        Parameters:
            None

        Returns:
            None
        """
        # Load the configuration file
        config_path = self.config_path

        if not os.path.exists(config_path):
            raise FileNotFoundError(
                f"Configuration file not found at {config_path}")

        config = configparser.ConfigParser()
        config.read(config_path)

        if 'feature' not in config:
            raise ValueError(f"Config file does not contain 'feature' section")

        feature_config = config['feature']

        # Set the configuration parameters
        self.sr = int(feature_config.get('sr', 16000))

    def _generate_zero_labels(self, start_time: float, end_time: float) -> np.ndarray:
        """
        Generate a zero label for the segment.

        Parameters:
            start_time (float): Start time of the segment.
            end_time (float): End time of the segment.

        Returns:
            np.ndarray: Zero label for the segment.
        """
        sample_rate = self.sr
        unique_labels = self.unique_labels
        start_frame = int(start_time * sample_rate)
        end_frame = int(end_time * sample_rate)

        labels = np.zeros(
            (end_frame - start_frame, len(unique_labels)), dtype=np.int32)

        return labels

    def _generate_labels_per_segment(self, feature_file: str, annotations_path: str, transcript_dir: str, label_dir: str) -> None:
        """
        Generate labels for each segment in the audio file. The labels are generated by checking if the segment contains the event.
        If the segment contains the event, the label is set to 1, otherwise the label is set to 0. The labels are saved in a .npy file.

        Parameters:
            feature_file (str): Path to the .npy file containing the features.
            annotations_path (str): Path to the csv file containing the annotations.
            transcript_dir (str): Directory containing the transcript files generated by WhisperX.
            label_dir (str): Directory where the labels will be saved.

        Returns:
            None
        """
        # Split the feature file name to get the audio file name and the segment number
        feature_file_name = os.path.basename(feature_file)
        parts = feature_file_name.rsplit('_', 1)
        audio_file_name = parts[0]
        segment_number = parts[1].replace('.npy', '')
        segment_index = int(segment_number) - 1

        # Search for the transcript file in the transcript directory and subdirectories
        # and find the start and end time of the segment
        transcript_file = None
        for root, _, files in os.walk(transcript_dir):
            for file in files:
                if audio_file_name in file:
                    transcript_file = os.path.join(root, file)

        if transcript_file is None:
            raise FileNotFoundError(
                f"Transcript file not found for {audio_file_name}")

        # Read the transcript file to find the start and end time of the segment
        start_time = 0
        end_time = 0
        with open(transcript_file, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            next(reader)  # Skip header
            for i, row in enumerate(reader):
                if i == segment_index:
                    start_time = float(row[0])
                    end_time = float(row[1])
                    break

        # Create a zero label for the segment
        labels = self._generate_zero_labels(start_time, end_time)

        # Read the annotations file to find the events in the segment
        annotations = pd.read_csv(annotations_path)
        for index, row in annotations.iterrows():
            annotation_file_name = os.path.basename(row['file']).split('.')[0]
            if annotation_file_name == audio_file_name:
                # Determine which row in the labels array corresponds to the event
                event_index = self.unique_labels.index(row['label'])

                # Check which segments contain the event
                # Three scenarios to consider:
                # 1. The event starts and ends within the segment
                # 2. The event starts before the segment and ends within the segment
                # 3. The event starts within the segment and ends after the segment
                if row['start'] >= start_time and row['end'] <= end_time:
                    start_frame = int((row['start'] - start_time) * self.sr)
                    end_frame = int((row['end'] - start_time) * self.sr)
                    labels[start_frame:end_frame, event_index] = 1

                elif row['start'] < start_time and row['end'] <= end_time and row['end'] > start_time:
                    start_frame = 0
                    end_frame = int((row['end'] - start_time) * self.sr)
                    labels[start_frame:end_frame, event_index] = 1

                elif row['start'] >= start_time and row['start'] < end_time and row['end'] > end_time:
                    start_frame = int((row['start'] - start_time) * self.sr)
                    end_frame = labels.shape[0]
                    labels[start_frame:end_frame, event_index] = 1

        # Save the labels in a .npy file
        feature_file_name = os.path.basename(feature_file)
        label_file_name = feature_file_name.replace('.npy', '_label.npy')
        label_file_path = os.path.join(label_dir, label_file_name)
        np.save(label_file_path, labels)

        # Count the number of events in the segment
        label_count = 0
        for i in range(labels.shape[1]):
            if np.sum(labels[:, i]) > 0:
                label_count += 1

        # Fill in the information in the labels_info_df
        if feature_file in self.labels_info_df['feature_file'].values:
            idx = self.labels_info_df[self.labels_info_df['feature_file']
                                      == feature_file].index[0]
            self.labels_info_df.at[idx, 'start_time'] = start_time
            self.labels_info_df.at[idx, 'end_time'] = end_time
            self.labels_info_df.at[idx, 'label_count'] = label_count

    def _generate_labels_for_single_list(self, list_features_files: List[str], annotations_path: str, transcript_dir: str, label_dir: str, index: int, file_per_process: int, feature_file_length: int) -> None:
        """
        Generate labels for a list of feature files. (Used for multiprocessing)

        Parameters:
            list_features_files (List[str]): List of feature files to generate labels for.
            annotations_path (str): Path to the csv file containing the annotations.
            transcript_dir (str): Directory containing the transcript files generated by WhisperX.
            label_dir (str): Directory where the labels will be saved.
            index (int): Index of the process.
            file_per_process (int): Number of files to process per process.
            feature_file_length (int): Number of feature files.

        Returns:
            None
        """
        process_index = index

        for sub_list_index, feature_file in enumerate(list_features_files):
            index = process_index * file_per_process + sub_list_index
            label_file_name = os.path.basename(
                feature_file).replace('.npy', '_label.npy')
            label_file_path = os.path.join(label_dir, label_file_name)

            print(
                f"Generating labels {index + 1}/{feature_file_length}: {feature_file}")

            if not os.path.exists(label_file_path):
                self._generate_labels_per_segment(
                    feature_file, annotations_path, transcript_dir, label_dir)
                print(
                    f"Generating labels {index + 1}/{feature_file_length}: {feature_file} completed")

            else:
                print(
                    f"Generating labels {index + 1}/{feature_file_length}: {feature_file} already exists")

    def generate_all_labels_multiprocessing(self, wav_list: str, annotations_path: str, transcript_dir: str, feature_dir: str, label_dir: str, label_info_dir: str, n_process: int) -> None:
        """
        Generate labels for all the audio files in the dataset. Creates a .npy file for each segment in the audio file.
        Each labels is stored in a dataframe with the following columns:
            - filename: the name of the audio file
            - start_time: the start time of the segment
            - end_time: the end time of the segment
            - label: the label of the segment (.npy file)

        (1) Read the annotations file and find the unique labels in the annotations file
        (2) Iterate through the list of wav files and transcript files to generate the zero labels for each segment in each audio file
        (3) Iterate through the annotations file to set the zero labels to 1 where the event is present
        (4) Save the labels in a .npy file
        (5) Save a csv file to list out how many events are present in each audio file

        Parameters:
            wav_list (str): List of audio files to extract features from.
            annotations_path (str): Path to the csv file containing the annotations.
            transcript_dir (str): Directory containing the transcript files generated by WhisperX.
            feature_dir (str): Directory containing the audio features (.npy files) generated by the feature extraction script.
            label_dir (str): Directory where the labels will be saved.
            label_info_dir (str): Directory where the labels information will be saved.
            n_process (int): Number of processes to use for feature extraction.

        Returns:
            None
        """
        if not os.path.exists(label_dir):
            os.makedirs(label_dir)

        paths = [annotations_path, transcript_dir, feature_dir]

        for path in paths:
            if not os.path.exists(path):
                raise FileNotFoundError(f'{path} not found.')

        # (1)
        # Read the annotations file into pandas dataframe
        annotations = pd.read_csv(annotations_path)

        # Check if the annotations file contains the required columns (file, label, start, end)
        required_columns = ['file', 'label', 'start', 'end']
        columns = annotations.columns.tolist()

        for column in required_columns:
            if column not in columns:
                raise ValueError(
                    f'{column} not found in the annotations file.')

        # Save the unique labels in the annotations file (types of speech errors)
        self.unique_labels = annotations['label'].unique().tolist()

        # (2)
        # Iterate through the list of wav files and create a pandas dataframe to store the information
        with open(wav_list, 'r') as f:
            wav_files = f.readlines()

        wav_list = [wav.strip() for wav in wav_files]

        self.labels_info_df = pd.DataFrame(
            columns=['feature_file', 'label_file', 'start_time', 'end_time', 'label_count'])

        # Generate a list of feature files from the feature directory and subdirectories (.npy files)
        feature_files = []
        label_files = []
        for root, _, files in os.walk(feature_dir):
            for file in files:
                if file.endswith('.npy'):
                    feature_files.append(os.path.join(root, file))
                    label_file_name = file.replace('.npy', '_label.npy')
                    label_files.append(os.path.join(
                        label_dir, label_file_name))

        # Put the feature files and label files in the DataFrame
        self.labels_info_df['feature_file'] = feature_files
        self.labels_info_df['label_file'] = label_files
        self.labels_info_df['start_time'] = [
            0.0 for _ in range(len(feature_files))]
        self.labels_info_df['end_time'] = [
            0.0 for _ in range(len(feature_files))]
        self.labels_info_df['label_count'] = [
            0 for _ in range(len(feature_files))]

        # (3) (4)
        # Generate labels for each segment in the audio file using multiprocessing
        # Split the feature files into n_process parts
        # Each process will generate labels for a certain number of the feature files
        # The results (labels) are saved in a .npy file
        file_per_process = (len(feature_files) + n_process - 1) // n_process

        processes = []
        for process_index in range(n_process):
            start_index = process_index * file_per_process
            end_index = min((process_index + 1) *
                            file_per_process, len(feature_files))

            # Check if the estart index is within the range of the feature files
            if start_index < len(feature_files) and start_index < end_index:
                feature_files_sub_list = feature_files[start_index:end_index]
                process = multiprocessing.Process(target=self._generate_labels_for_single_list, args=(
                    feature_files_sub_list, annotations_path, transcript_dir, label_dir, process_index, file_per_process, len(feature_files)))

                # Start the process
                process.start()
                processes.append(process)
                print(
                    f"Process {process_index + 1}/{min(n_process, len(feature_files))} started")

        # Ensure all processes have finished
        for process in processes:
            process.join()

        # (5)
        # Save the labels information in a csv file
        labels_info_path = os.path.join(label_info_dir, 'labels_info.csv')
        self.labels_info_df.to_csv(labels_info_path, index=False)
        print(self.labels_info_df.head())
        print(f"Labels information saved to {labels_info_path}")

    def generate_all_labels_single_process(self, wav_list: str, annotations_path: str, transcript_dir: str, feature_dir: str, label_dir: str, label_info_dir: str) -> None:
        if not os.path.exists(label_dir):
            os.makedirs(label_dir)

        paths = [annotations_path, transcript_dir, feature_dir]

        for path in paths:
            if not os.path.exists(path):
                raise FileNotFoundError(f'{path} not found.')

        # (1)
        # Read the annotations file into pandas dataframe
        annotations = pd.read_csv(annotations_path)

        # Check if the annotations file contains the required columns (file, label, start, end)
        required_columns = ['file', 'label', 'start', 'end']
        columns = annotations.columns.tolist()

        for column in required_columns:
            if column not in columns:
                raise ValueError(
                    f'{column} not found in the annotations file.')

        # Save the unique labels in the annotations file (types of speech errors)
        self.unique_labels = annotations['label'].unique().tolist()

        # (2)
        # Iterate through the list of wav files and create a pandas dataframe to store the information
        with open(wav_list, 'r') as f:
            wav_files = f.readlines()

        wav_list = [wav.strip() for wav in wav_files]

        self.labels_info_df = pd.DataFrame(
            columns=['feature_file', 'label_file', 'start_time', 'end_time', 'label_count'])

        # Generate a list of feature files from the feature directory and subdirectories (.npy files)
        feature_files = []
        label_files = []
        for root, _, files in os.walk(feature_dir):
            for file in files:
                if file.endswith('.npy'):
                    feature_files.append(os.path.join(root, file))
                    label_file_name = file.replace('.npy', '_label.npy')
                    label_files.append(os.path.join(
                        label_dir, label_file_name))

        # Put the feature files and label files in the DataFrame
        self.labels_info_df['feature_file'] = feature_files
        self.labels_info_df['label_file'] = label_files
        self.labels_info_df['start_time'] = [
            0.0 for _ in range(len(feature_files))]
        self.labels_info_df['end_time'] = [
            0.0 for _ in range(len(feature_files))]
        self.labels_info_df['label_count'] = [
            0 for _ in range(len(feature_files))]

        # (3) (4)
        # Generate labels for each segment in the audio file without multiprocessing
        for index, feature_file in enumerate(feature_files):
            print(
                f"Processing {index + 1}/{len(feature_files)}: {feature_file}")
            self._generate_labels_for_single_list(
                [feature_file], annotations_path, transcript_dir, label_dir, index, 1, len(
                    feature_files)
            )

        # (5)
        # Save the labels information in a csv file
        labels_info_path = os.path.join(label_info_dir, 'labels_info.csv')
        self.labels_info_df.to_csv(labels_info_path, index=False)
        print(self.labels_info_df.head())
        print(f"Labels information saved to {labels_info_path}")


def generate_label(wav_list: str, annotation_path: str, transcript_dir: str, feature_dir: str, label_dir: str, label_info_dir: str, feature_config: str, n_process: int) -> None:
    """
    Generate labels for the training data. The labels are generated from a csv file and the resulting labels are saved to disk in a .npy file.

    Parameters:
        wav_list (str): List of audio files to extract features from.
        annotation_path (str): Path to the csv file containing the annotations.
        transcript_dir (str): Directory containing the transcript files generated by WhisperX.
        feature_dir (str): Directory containing the audio features (.npy files) generated by the feature extraction script.
        label_dir (str): Directory where the labels will be saved.
        label_info_dir (str): Directory where the labels information will be saved.
        feature_config (str): Path to the feature configuration file.
        n_process (int): Number of processes to use for feature extraction.

    Returns:
        None
    """
    label_encoder = LabelEncoder(feature_config)
    # label_encoder.generate_all_labels_multiprocessing(
    #     wav_list, annotation_path, transcript_dir, feature_dir, label_dir, label_info_dir, n_process)
    label_encoder.generate_all_labels_single_process(
        wav_list, annotation_path, transcript_dir, feature_dir, label_dir, label_info_dir)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='Generate labels for the training data.')
    parser.add_argument('--wav_list', type=str, dest='wav_list',
                        help='List of audio files to extract features from.', required=True)
    parser.add_argument('--annotation_path', type=str,
                        help='Path to the csv file containing the annotations', required=True)
    parser.add_argument('--transcript_dir', type=str,
                        help='Directory containing the transcript files generated by WhisperX', required=True)
    parser.add_argument('--feature_dir', type=str,
                        help='Directory containing the audio features (.npy files) generated by the feature extraction script', required=True)
    parser.add_argument('--label_dir', type=str,
                        help='Directory where the labels will be saved', required=True)
    parser.add_argument('--label_info_dir', type=str,
                        help='Directory where the labels information will be saved', required=True)
    parser.add_argument('--feature_config', type=str,
                        help='Path to the feature configuration file', required=True)
    parser.add_argument('--n_process', type=int, dest='n_process',
                        help='Number of processes to use for feature extraction.', default=4)

    arguments = parser.parse_args()

    wav_list = arguments.wav_list
    annotation_path = arguments.annotation_path
    transcript_dir = arguments.transcript_dir
    feature_dir = arguments.feature_dir
    label_dir = arguments.label_dir
    label_info_dir = arguments.label_info_dir
    feature_config = arguments.feature_config
    n_process = arguments.n_process

    paths = [wav_list, annotation_path, transcript_dir,
             feature_dir, label_dir, label_info_dir, feature_config]

    for path in paths:
        if not os.path.exists(path):
            raise FileNotFoundError(f'Path "{path}" not found.')

    generate_label(wav_list, annotation_path, transcript_dir,
                   feature_dir, label_dir, label_info_dir, feature_config, n_process)
