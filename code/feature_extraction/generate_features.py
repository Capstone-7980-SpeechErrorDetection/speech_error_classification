"""
This script is used to extract features from audio files and save them to disk. The features are extracted using the Mel spectrogram method.
Each array represents a phrase in the audio file (padded to 10 seconds). The features are saved in a .npy file. The phrases are extracted from the audio file using
the timestamps provided in the transcript file generated by WhisperX. Each line in the transcript file contains the following information:
    - start: the start time of the audio segment
    - end: the end time of the audio segment
    - text: the text of the audio segment
The .csv file names must match the audio file names.

Usage:
    python generate_features.py --wav_list <wav_list> --wav_dir <wav_dir> --transcript_dir <transcript_dir> --feature_dir <feature_dir> --feature_config <feature_config> --n_process <n_process> --feature_config <feature_config> --n_process <n_process>
    
    - wav_list (str): List of audio files to extract features from.
    - wav_dir (str): Directory containing the audio files.
    - transcript_dir (str): Directory containing the transcript files.
    - feature_dir (str): Directory to save the extracted features.
    - feature_config (str): Path to the feature extraction configuration file.
    - n_process (int): Number of processes to use for feature extraction.
    
Example:
    python generate_features.py --wav_list data/metadata/wav_list.lst --wav_dir data/audio --transcript_dir data/whisperX --feature_dir data/feature --feature_config feature_extraction/feature.cfg --n_process 4

References:
    - (https://github.com/Kikyo-16/Sound_event_detection/blob/master/feature_extraction/gen_feature.py)
"""


import os
import configparser
from typing import List
import argparse
import multiprocessing
import librosa
import scipy
import numpy as np
import csv


class FeatureExtractor():
    def __init__(self, config_path: str) -> None:
        """
        FeatureExtractor Class
        ======================

        The FeatureExtractor class is used to extract features from audio files and save them to disk.

        Public Methods
        --------------
        - generate_feature_multiprocessing(list: List[str], wav_dir: str, transcript_dir: str, feature_dir: str, n_process: int) -> None:

        Public Properties
        -----------------
        - n_fft: Number of points in the Fast Fourier Transform.
        - win_length: Window length in seconds.
        - hop_length: Hop length in seconds.
        - sr: Sampling rate of the audio files.
        - n_mels: Number of Mel bands to generate.
        - f_min: Minimum frequency.
        - f_max: Maximum frequency.
        - frame_length: Length of the frame.
        - win_length_seconds: Window length in seconds.
        - hop_length_seconds: Hop length in seconds.

        Dependencies
        ------------
        - [os](https://docs.python.org/3/library/os.html)
        - [configparser](https://docs.python.org/3/library/configparser.html)
        - [numpy](https://numpy.org/)
        - [librosa](https://librosa.org/doc/main/index.html)
        - [scipy](https://docs.scipy.org/doc/scipy/reference/index.html)
        - [multiprocessing](https://docs.python.org/3/library/multiprocessing.html)
        - [typing](https://docs.python.org/3/library/typing.html)

        References:
        -----------
        - (https://github.com/Kikyo-16/Sound_event_detection/blob/master/feature_extraction/gen_feature.py)

        """
        self.config_path = config_path
        self.n_fft = None
        self.win_length = None
        self.hop_length = None
        self.sr = None
        self.n_mels = None
        self.f_min = None
        self.f_max = None
        self.frame_length = None
        self.win_length_seconds = None
        self.hop_length_seconds = None

        # Initialize the feature extraction configuration
        self._init_config()

    def _init_config(self) -> None:
        """
        Initialize the feature extraction configuration file.

        Parameters:
            None

        Return:
            None
        """
        # Load the configuration file
        config_path = self.config_path

        if not os.path.exists(config_path):
            raise FileNotFoundError(f"Config file not found at {config_path}")

        config = configparser.ConfigParser()
        config.read(config_path)

        if 'feature' not in config:
            raise ValueError(f"Config file does not contain 'feature' section")

        feature_config = config['feature']

        # Set the configuration parameters
        self.n_fft = int(feature_config.get('n_fft', 2048))
        self.win_length = float(feature_config.get('win_length', 0.04))
        self.hop_length = float(feature_config.get('hop_length', 0.02))
        self.sr = int(feature_config.get('sr', 16000))
        self.n_mels = int(feature_config.get('n_mels', 64))
        self.f_min = int(feature_config.get('f_min', 0))
        self.f_max = int(feature_config.get('f_max', 22050))

        if self.f_min < 0 or self.f_min > self.f_max or self.f_max > self.sr / 2:
            raise ValueError(
                f"Invalid frequency range: {self.f_min} to {self.f_max}")

        self.output_frames = int(feature_config.get('LEN', 400))

        # Calculate the frame length, window length, and hop length in seconds
        self.win_length_seconds = int(self.win_length * self.sr)
        self.hop_length_seconds = int(self.hop_length * self.sr)

    def _get_feature(self, input_file: str, output_file: str, transcript_file: str, fixed_length: bool = True, length_in_seconds: int = 10) -> np.ndarray:
        """
        Extract features from an audio file and save them to disk.

        Parameters:
            input_file (str): Path to the input audio file.
            output_file (str): Path to save the extracted features.
            transcript_file (str): Path to the transcript file.
            fixed_length (bool): Whether to pad/squeeze segments to a fixed length.
            length_in_seconds (int): The fixed length to pad/squeeze to, in seconds.

        Return:
            feature_output (np.ndarray): Extracted features from the audio file.
        """
        sampling_rate = self.sr
        n_fft = self.n_fft  # number of points in the Fast Fourier Transform
        n_mels = self.n_mels  # number of Mel bands to generate
        f_min = self.f_min  # minimum frequency
        f_max = self.f_max  # maximum frequency
        win_length_seconds = self.win_length_seconds  # window length in seconds
        hop_length_seconds = self.hop_length_seconds  # hop length in seconds
        output_length = self.output_frames  # number of frames to output

        if win_length_seconds > n_fft:
            raise ValueError(
                f"Window length {win_length_seconds} is greater than n_fft {n_fft}\nIncrease n_fft or decrease win_length")

        # Read the transcript file (.csv)
        segments = []
        with open(transcript_file, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            next(reader)  # Skip header
            for row in reader:
                start_time = float(row[0])
                end_time = float(row[1])
                segments.append((start_time, end_time))

        # Load the audio file
        y, sr = librosa.load(input_file, sr=sampling_rate)

        features_list = []
        for start_time, end_time in segments:
            # Extract the segment
            segment = y[int(start_time * sr):int(end_time * sr)]

            # Pad the segment if it is shorter than n_fft
            if len(segment) < n_fft:
                segment = np.pad(
                    segment, (0, n_fft - len(segment)), mode='constant')

            # Apply Hanning window
            window = scipy.signal.windows.hann(win_length_seconds, sym=False)

            # Compute the Mel spectrogram
            mel_basis = librosa.filters.mel(
                sr=sr, n_fft=n_fft, n_mels=n_mels, fmin=f_min, fmax=f_max)
            epsilon = np.spacing(1)
            spectrogram = librosa.stft(
                segment + epsilon, n_fft=n_fft, hop_length=hop_length_seconds,
                win_length=win_length_seconds, window=window)
            spectrogram = np.abs(spectrogram)
            mel_spectrogram = np.dot(mel_basis, spectrogram)
            log_mel_spectrogram = np.log(mel_spectrogram + epsilon)

            feature = np.transpose(log_mel_spectrogram)

            if fixed_length:
                # Use 10 seconds of audio as input
                frame_length = int(
                    sampling_rate * length_in_seconds / hop_length_seconds + 1)
                feature_temp = np.zeros((frame_length, feature.shape[1]))

                if feature.shape[0] < frame_length:
                    feature_temp[:feature.shape[0]] = feature
                else:
                    feature_temp = feature[:frame_length]

                feature_output = np.zeros((output_length, feature.shape[1]))

                # When the frame length does not match the output length
                if frame_length != output_length:
                    if frame_length < output_length:
                        # Pad and center the feature
                        start_index = (output_length - frame_length) // 2
                        end_index = start_index + frame_length
                        feature_output[start_index:end_index] = feature_temp
                    else:
                        # Crop the feature
                        start_index = (frame_length - output_length) // 2
                        end_index = start_index + output_length
                        feature_output = feature_temp[start_index:end_index]
                else:
                    feature_output = feature_temp

                features_list.append(feature_output)
            else:
                features_list.append(feature)

        # Save the extracted features to disk
        for i, feature in enumerate(features_list):
            np.save(f"{output_file.split('.')[0]}_{i+1}.npy", feature)

        return features_list

    def _get_feature_for_single_list(self, list_audio_files: List[str], wav_dir: str, transcript_dir: str, feature_dir: str, index: int, file_per_process: int, wav_list_length: int) -> None:
        """
        Extract features for a list of audio files and save them to disk.

        Parameters:
            list_audio_files (list): List of audio files to extract features from.
            wav_dir (str): Directory containing the audio files.
            transcript_dir (str): Directory containing the transcript files.
            feature_dir (str): Directory to save the extracted features.
            index (int): Index of the list of audio files.
            file_per_process (int): Number of files per process.
            wav_list_length (int): Total number of audio files.

        Return:
            None
        """
        for sub_list_index, file in enumerate(list_audio_files):
            index = index * file_per_process + sub_list_index
            input_file = os.path.join(wav_dir, file)
            output_file = os.path.join(feature_dir, file)
            output_file_name_prefix = os.path.basename(
                output_file).split('.')[0]
            print(
                f"Extracting features {index + 1}/{wav_list_length}: {input_file}")

            # Find the corresponding transcript file in subdirectory
            transcript_file_name = file.replace('.wav', '.csv')
            transcript_file = self._find_transcript_file(
                transcript_dir, transcript_file_name)
            if not transcript_file:
                print(f"transcript file not found for {input_file}")
                continue

            if not file_exists_with_prefix(feature_dir, output_file_name_prefix):
                self._get_feature(input_file, output_file,
                                  transcript_file, fixed_length=False)
                print(
                    f"Extracting features {index + 1}/{wav_list_length}: {input_file} completed")
            else:
                print(
                    f"Extracting features {index + 1}/{wav_list_length}: {input_file} already exists")

    def generate_feature_multiprocessing(self, list_audio_files: List[str], wav_dir: str, transcript_dir: str, feature_dir: str, n_process: int) -> None:
        """
        Extract features for a list of audio files using multiprocessing.

        Parameters:
            list_audio_files (list): List of audio files to extract features from.
            wav_dir (str): Directory containing the audio files.
            transcript_dir (str): Directory containing the transcript files.
            feature_dir (str): Directory to save the extracted features.
            n_process (int): Number of processes to use for feature extraction.

        Return:
            None
        """
        with open(list_audio_files, 'r') as f:
            wav_list = f.readlines()

        wav_list = [wav.strip() for wav in wav_list]

        file_per_process = (len(wav_list) + n_process - 1) // n_process

        for process_index in range(n_process):
            start_index = process_index * file_per_process
            end_index = min((process_index + 1) *
                            file_per_process, len(wav_list))

            # Check if the start index is within the list
            if start_index < len(wav_list) and start_index < end_index:
                sub_list = wav_list[start_index:end_index]
                process = multiprocessing.Process(target=self._get_feature_for_single_list, args=(
                    sub_list, wav_dir, transcript_dir, feature_dir, process_index, file_per_process, len(wav_list)))

                # Start the process
                process.start()
                print(
                    f"Process {process_index + 1}/{min(n_process, len(wav_list))} started")

    def _find_transcript_file(self, transcript_dir: str, transcript_file_name: str) -> str:
        """
        Find the transcript file in the directory.

        Parameters:
            transcript_dir (str): Directory containing the transcript files.
            transcript_file_name (str): Name of the transcript file.

        Return:
            transcript_file (str): Path to the transcript file.
        """
        for root, dirs, files in os.walk(transcript_dir):
            if transcript_file_name in files:
                return os.path.join(root, transcript_file_name)
        return None


def file_exists_with_prefix(directory, output_file_prefix):
    for filename in os.listdir(directory):
        if filename.startswith(output_file_prefix):
            return True
    return False


def extract_feature(wav_list: List[str], wav_dir: str, transcript_dir: str, feature_dir: str, feature_config_path: str, n_process: int) -> None:
    """
    Generate features for a list of audio files and save them to disk.

    Parameters:
        wav_list (list): List of audio files to extract features from.
        wav_dir (str): Directory containing the audio files.
        transcript_dir (str): Directory containing the transcript files.
        feature_dir (str): Directory to save the extracted features.
        feature_config_path (str): Path to the feature extraction configuration file.
        n_process (int): Number of processes to use for feature extraction.

    Return:
        None
    """
    feature_extractor = FeatureExtractor(feature_config_path)
    feature_extractor.generate_feature_multiprocessing(
        wav_list, wav_dir, transcript_dir, feature_dir,  n_process)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='Extract features from audio files and save them to disk.')
    parser.add_argument('--wav_list', type=str, dest='wav_list',
                        help='List of audio files to extract features from.', required=True)
    parser.add_argument('--wav_dir', type=str, dest='wav_dir',
                        help='Directory containing the (.wav) audio files.', required=True)
    parser.add_argument('--transcript_dir', type=str, dest='transcript_dir',
                        help='Directory containing the (.csv) transcript files.', required=True)
    parser.add_argument('--feature_dir', type=str, dest='feature_dir',
                        help='Directory to save the extracted features.', required=True)
    parser.add_argument('--feature_config', type=str, dest='feature_config',
                        help='Path to the feature extraction configuration file.', required=True)
    parser.add_argument('--n_process', type=int, dest='n_process',
                        help='Number of processes to use for feature extraction.', default=4)

    arguments = parser.parse_args()

    wav_list = arguments.wav_list
    wav_dir = arguments.wav_dir
    transcript_dir = arguments.transcript_dir
    feature_dir = arguments.feature_dir
    feature_config = arguments.feature_config
    n_process = arguments.n_process

    paths = [wav_list, wav_dir, transcript_dir, feature_dir, feature_config]

    for path in paths:
        if not os.path.exists(path):
            raise FileNotFoundError(f'Path "{path}" not found.')

    extract_feature(wav_list, wav_dir, transcript_dir,
                    feature_dir, feature_config, n_process)
